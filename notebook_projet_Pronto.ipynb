{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abad37f",
   "metadata": {},
   "source": [
    "## Definite SMPLX class for SMPLX model\n",
    "\n",
    "cette parrtie sert a reccuperer les donnés de laa base de donnné CMU pour ensiute les traiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from body_model import BodyModel\n",
    "from utils import rodrigues_2_rot_mat  \n",
    "from lbs import lbs, batch_rodrigues  \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# recuperation du fichier MALE SMPLX \n",
    "# /!\\ Attention : cela depend de l'arborescence de votre projet\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# On remonte d’un niveau dans l’arborescence des dossiers à partir du répertoire courant\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Chemin absolu vers le fichier du modèle SMPLX\n",
    "SMPLX_MODEL_MALE_PATH = os.path.join(\n",
    "    PROJECT_ROOT,\n",
    "    'test smplx/smplx_lockedhead_20230207/models_lockedhead/smplx/SMPLX_MALE.npz'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "class SMPLX(BodyModel):\n",
    "    def __init__(self, num_betas=16, **kwargs):\n",
    "        # Initialisation du modèle SMPLX à partir du fichier .npz\n",
    "        super().__init__(\n",
    "            bm_fname=SMPLX_MODEL_MALE_PATH,\n",
    "            num_betas=num_betas,\n",
    "            num_expressions=0,  \n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def forward(self, pose_body, betas, use_rodrigues=True):\n",
    "        \"\"\"\n",
    "        Génère une sortie 3D (vertices, joints, faces) à partir d'un vecteur de pose et de paramètres de forme.\n",
    "        \n",
    "        pose_body : [B, 66]  -> 22 articulations * 3 (Rodrigues ou rot6d)\n",
    "        betas     : [B, 16]  -> Coefficients de forme\n",
    "        \"\"\"\n",
    "\n",
    "        device = pose_body.device\n",
    "\n",
    "        \n",
    "        for name in [\n",
    "            'init_pose_hand', 'init_pose_jaw', 'init_pose_eye',\n",
    "            'init_v_template', 'init_expression', 'shapedirs',\n",
    "            'exprdirs', 'posedirs', 'J_regressor',\n",
    "            'kintree_table', 'weights', 'f'\n",
    "        ]:\n",
    "            tensor = getattr(self, name)\n",
    "            setattr(self, name, tensor.to(device))\n",
    "\n",
    "        batch_size = pose_body.shape[0]\n",
    "\n",
    "        # Initialisation des poses neutres pour les mains, la mâchoire, les yeux\n",
    "        pose_hand = self.init_pose_hand.expand(batch_size, -1)\n",
    "        pose_jaw = self.init_pose_jaw.expand(batch_size, -1)\n",
    "        pose_eye = self.init_pose_eye.expand(batch_size, -1)\n",
    "\n",
    "        # Template de vertices et d'expression neutre\n",
    "        v_template = self.init_v_template.expand(batch_size, -1, -1)\n",
    "        expression = self.init_expression.expand(batch_size, -1)\n",
    "\n",
    "        \n",
    "        init_pose = torch.cat([pose_jaw, pose_eye, pose_hand], dim=-1)  # [B, 99]\n",
    "        if not use_rodrigues:\n",
    "            init_pose = rodrigues_2_rot_mat(init_pose)  # [B, 33, 3, 3]\n",
    "\n",
    "        full_pose = torch.cat([pose_body, init_pose], dim=-1)  # [B, 165]\n",
    "\n",
    "        shape_components = torch.cat([betas, expression], dim=-1)\n",
    "\n",
    "        shapedirs = torch.cat([self.shapedirs, self.exprdirs], dim=-1)\n",
    "\n",
    "        # ------------------------------\n",
    "        # Appel au Linear Blend Skinning (déformation du maillage)\n",
    "        # ------------------------------\n",
    "        verts, joints = lbs(\n",
    "            betas=shape_components,\n",
    "            pose=full_pose,\n",
    "            v_template=v_template,\n",
    "            shapedirs=shapedirs,\n",
    "            posedirs=self.posedirs,\n",
    "            J_regressor=self.J_regressor,\n",
    "            parents=self.kintree_table[0].long(),\n",
    "            lbs_weights=self.weights,\n",
    "            pose2rot=use_rodrigues\n",
    "        )\n",
    "\n",
    "        # Récupération des faces du mesh, répétées pour chaque instance du batch\n",
    "        faces = self.f.expand(batch_size, -1, -1)\n",
    "\n",
    "\n",
    "        return dict(verts=verts, faces=faces, joints=joints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "smplx = SMPLX().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345272c",
   "metadata": {},
   "source": [
    "### Fonctions pour visualiser le body : une qui permet de visualiser les frame et une qui visualise l'animation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiser le nuage de points avant et après translation\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualize_frame(verts, trans):\n",
    "    # visualiser le mesh\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "    ax1.scatter(verts[:, 0], verts[:, 1], verts[:, 2], c='gray', marker='o', s=0.01)\n",
    "    ax1.set_title(\"Mesh before translation\")\n",
    "    val_min = verts.min()\n",
    "    val_max = verts.max()\n",
    "    ax1.set_xlim(val_min, val_max)\n",
    "    ax1.set_ylim(val_min, val_max)\n",
    "    ax1.set_zlim(val_min, val_max)\n",
    "\n",
    "\n",
    "    verts_ = verts + trans \n",
    "    ax2.scatter(verts_[:, 0], verts_[:, 1], verts_[:, 2], c='gray', marker='o', s=0.01)\n",
    "    ax2.set_title(\"Mesh after translation\")\n",
    "    val_min = verts_.min()\n",
    "    val_max = verts_.max()\n",
    "    ax2.set_xlim(val_min, val_max)\n",
    "    ax2.set_ylim(val_min, val_max)\n",
    "    ax2.set_zlim(val_min, val_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiser la suite de nuages de points et de meshes de mouvement\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def visualize_seq(verts, faces):\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax_pc = fig.add_subplot(121, projection='3d')\n",
    "    ax_mesh = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "    total_frames = len(verts)\n",
    "\n",
    "    def update_view(frame):\n",
    "        ax_pc.cla()\n",
    "        ax_mesh.cla()\n",
    "\n",
    "        val_min = verts.min()\n",
    "        val_max = verts.max()\n",
    "\n",
    "        # Extrait le nuage de points et theta pour la frame actuelle\n",
    "        gt_pc = verts[frame].cpu().numpy()\n",
    "\n",
    "        # affiche le nuage de points\n",
    "        ax_pc.scatter(gt_pc[:, 0], gt_pc[:, 1], gt_pc[:, 2], s=0.01, c='gray')\n",
    "        ax_pc.set_title(f\"Point Cloud Frame {frame + 1}\")\n",
    "        ax_pc.set_xlim(val_min, val_max)\n",
    "        ax_pc.set_ylim(val_min, val_max)\n",
    "        ax_pc.set_zlim(val_min, val_max)\n",
    "        ax_pc.view_init(elev=20, azim=50)\n",
    "\n",
    "\n",
    "        # affiche le mesh\n",
    "        ax_mesh.plot_trisurf(gt_pc[:, 0], gt_pc[:, 1], gt_pc[:, 2], triangles=faces, color='green', alpha=0.2)\n",
    "        ax_mesh.set_title(f\"Mesh Frame {frame + 1}\")\n",
    "        ax_mesh.set_xlim(val_min, val_max)\n",
    "        ax_mesh.set_ylim(val_min, val_max)\n",
    "        ax_mesh.set_zlim(val_min, val_max)\n",
    "        ax_mesh.view_init(elev=20, azim=50)\n",
    "\n",
    "    #créé une animation pour toutes les frames de tous les batches\n",
    "    ani = FuncAnimation(fig, update_view, frames=total_frames)\n",
    "    plt.close(fig)  # ferme la figure pour eviter d'afficher un plot immobile \n",
    "\n",
    "    return ani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4063055b",
   "metadata": {},
   "source": [
    "### Charge les data CMU et créé le Mesh en uttilisant le model SMPLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHARGER LE JEU DE DONNÉES CMU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Charger le fichier npz\n",
    "npz_file_path = \"CMU/01/01_02_poses.npz\"\n",
    "npz_smplx = \"smplx_lockedhead_20230207/models_lockedhead/smplx/SMPLX_MALE.npz\"\n",
    "npz_file = np.load(npz_file_path)#, allow_pickle=True)\n",
    "npz_file_smplx = np.load(npz_smplx, allow_pickle=True)  \n",
    "\n",
    "# Extraire les données\n",
    "print(\"Extraction des données...\")\n",
    "data = {}\n",
    "for key in npz_file.keys():\n",
    "    print(f\"Clé : {key}\")\n",
    "    try : \n",
    "        if npz_file[key].shape == ():\n",
    "            print(f\"Contenu : {npz_file[key]}\")\n",
    "        else:\n",
    "            print(f\"Forme : {npz_file[key].shape}\")\n",
    "    except:\n",
    "        continue\n",
    "    data[key] = npz_file[key]\n",
    "    print(data[key].shape)\n",
    "print(\"Données extraites.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dab373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les MAILLAGES\n",
    "pose_body = torch.tensor(data['poses'][:-1, :66], dtype=torch.float32).to(device)  # 21 articulations (63 vecteurs)\n",
    "beta = torch.tensor(data['betas'], dtype=torch.float32).unsqueeze(0).repeat(pose_body.shape[0], 1).to(device)\n",
    "\n",
    "meshes = smplx(pose_body=pose_body, betas=beta, use_rodrigues=True)\n",
    "verts = meshes['verts']  # .verts_padded()\n",
    "faces = meshes['faces']  # .faces_packed()\n",
    "trans = data['trans']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e37b9",
   "metadata": {},
   "source": [
    "### VISUALISER UNE POSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141db35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VUSUALISER UNE POSE \n",
    "f = 0\n",
    "visualize_frame(verts[f], trans[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALISER UNE SUITE\n",
    "\n",
    "train_animation = visualize_seq(verts[:3000:40], faces[0])\n",
    "display(HTML(train_animation.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d36fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_seq_with_translation(verts, faces, trans):\n",
    "    from matplotlib.animation import FuncAnimation\n",
    "    from IPython.display import HTML\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax_pc = fig.add_subplot(121, projection='3d')\n",
    "    ax_mesh = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "    total_frames = len(verts)\n",
    "\n",
    "    def update_view(frame):\n",
    "        ax_pc.cla()\n",
    "        ax_mesh.cla()\n",
    "\n",
    "        val_min=verts.min().item()-0.7\n",
    "        val_max=verts.max().item()+0.7\n",
    "\n",
    "\n",
    "        # Apply translation to the current frame\n",
    "        translated_verts = verts[frame] + trans[frame]\n",
    "\n",
    "        gt_pc = translated_verts.cpu().numpy()\n",
    "\n",
    "        # Point cloud\n",
    "        ax_pc.scatter(gt_pc[:, 0], gt_pc[:, 1], gt_pc[:, 2], s=0.01, c='gray')\n",
    "        ax_pc.set_title(f\"Point Cloud Frame {frame + 1}\")\n",
    "        ax_pc.set_xlim(val_min, val_max)\n",
    "        ax_pc.set_ylim(val_min, val_max)\n",
    "        ax_pc.set_zlim(val_min, val_max)\n",
    "        ax_pc.view_init(elev=20, azim=50)\n",
    "\n",
    "        # Mesh\n",
    "        ax_mesh.plot_trisurf(gt_pc[:, 0], gt_pc[:, 1], gt_pc[:, 2], triangles=faces, color='green', alpha=0.2)\n",
    "        ax_mesh.set_title(f\"Mesh Frame {frame + 1}\")\n",
    "        ax_mesh.set_xlim(val_min, val_max)\n",
    "        ax_mesh.set_ylim(val_min, val_max)\n",
    "        ax_mesh.set_zlim(val_min, val_max)\n",
    "        ax_mesh.view_init(elev=20, azim=50)\n",
    "\n",
    "    ani = FuncAnimation(fig, update_view, frames=total_frames)\n",
    "    plt.close(fig)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc094b49",
   "metadata": {},
   "source": [
    "# 2. CODE POUR LIRE LES DONNÉS CMU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f9d7c",
   "metadata": {},
   "source": [
    "### Load one sequence of CMU data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the npz file\n",
    "npz_file_path = \"CMU/01/01_02_poses.npz\"\n",
    "npz_smplx = \"smplx_lockedhead_20230207/models_lockedhead/smplx/SMPLX_MALE.npz\"\n",
    "npz_file = np.load(npz_file_path)#, allow_pickle=True)\n",
    "npz_file_smplx = np.load(npz_smplx, allow_pickle=True)  \n",
    "\n",
    "# Extract the data\n",
    "print(\"Extracting data...\")\n",
    "data = {}\n",
    "for key in npz_file.keys():\n",
    "    print(f\"Key: {key}\")\n",
    "    try : \n",
    "        if npz_file[key].shape == ():\n",
    "            print(f\"Content: {npz_file[key]}\")\n",
    "        else:\n",
    "            print(f\"Shape: {npz_file[key].shape}\")\n",
    "    except:\n",
    "         \n",
    "        continue\n",
    "    data[key] = npz_file[key]\n",
    "    print(data[key].shape)\n",
    "print(\"Data extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c710a27c",
   "metadata": {},
   "source": [
    "### RECUPERER LA TRANSLATATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = data['trans']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410fd38a",
   "metadata": {},
   "source": [
    "### Visualier la transation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e406715",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(trans[:,0], trans[:,1], trans[:,2], s=1, label='translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ebd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "text = \"The boy goes to the sofa, then he sits on the chair and finally he lays on the bed.\"\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    " base_url=\"https://openrouter.ai/api/v1\",\n",
    " api_key=\"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\",\n",
    ")\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    " model=\"cognitivecomputations/dolphin3.0-r1-mistral-24b:free\",\n",
    " messages=[\n",
    "   {\n",
    "     \"role\": \"user\",\n",
    "     \"content\": \"You are an assistant that helps people find objects in a room. You should determine targets objects in the text description that we will give you.\"},\n",
    "               {\n",
    "                   \"role\": \"assistant\",\n",
    "                   \"content\": \"\"\"\n",
    "                       Here are the examples:\n",
    "                     \n",
    "                       Please note that targets should be split by \",\".\n",
    "                       1. Walk next to the bed and then sit on the chair. Please answer:\n",
    "                           bed,chair\n",
    "                       2. Sit on the sofa that is next to the table and head to the door. Please answer:\n",
    "                           sofa,table,door\n",
    "                       3. sit on the chair that is next to the table. Please answer:\n",
    "                           chair\n",
    "                       4. Stand up from the chair that is next to the tables and go to the toilet. Please answer:\n",
    "                           toilet\n",
    "                   \"\"\",\n",
    "               },\n",
    "               {\n",
    "                   \"role\": \"user\",\n",
    "                   \"content\": f\"\"\"\n",
    "                       The text description is: {text}.\n",
    "                       Answer in English.\n",
    "                       Answer should be in the following format without any explanations: target_object_1, target_object_2, target_object_3, ....\n",
    "                       Don't give the anchor object, only targets, if an object is used to find the position of an another one, don't give it like exemple 3.\n",
    "                       If there is no object in the text, return : error \n",
    "                   \"\"\",\n",
    "               }\n",
    "           ]\n",
    ")\n",
    "\n",
    "\n",
    "answer=completion.choices[0].message.content\n",
    "print(answer)\n",
    "names = answer.split(\",\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cae268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Chargement des fichiers de données .npz :\n",
    "# - npz_file contient les poses du dataset CMU\n",
    "# - npz_file_smplx contient les paramètres du modèle SMPLX\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "npz_file_path = \"CMU/01/01_02_poses.npz\"\n",
    "npz_smplx = \"smplx_lockedhead_20230207/models_lockedhead/smplx/SMPLX_MALE.npz\"\n",
    "npz_file = np.load(npz_file_path)  # Chargement du fichier de poses\n",
    "npz_file_smplx = np.load(npz_smplx, allow_pickle=True)  # Chargement du modèle SMPLX\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Extraction des données du fichier de poses CMU\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(\"Extraction des données...\")\n",
    "data = {}\n",
    "for key in npz_file.keys():\n",
    "    print(f\"Clé : {key}\")\n",
    "    try:\n",
    "        if npz_file[key].shape == ():  \n",
    "            print(f\"Contenu : {npz_file[key]}\")\n",
    "        else:  # Si tableau\n",
    "            print(f\"Forme : {npz_file[key].shape}\")\n",
    "    except:\n",
    "        continue\n",
    "    data[key] = npz_file[key]\n",
    "    print(data[key].shape)\n",
    "print(\"Données extraites.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Analyse des translations :\n",
    "# - On récupère la liste des translations 'trans'\n",
    "# - On calcule les coordonnées cumulées (x, y, z)\n",
    "# - On détermine des positions de référence espacées régulièrement\n",
    "# - On stocke aussi les déplacements relatifs entre chaque frame\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "coor = []           # Liste des positions cumulées toutes les n frames\n",
    "lcoor = []          # Liste temporaire pour stocker les difference de positions\n",
    "lfinale = []        # Liste de toutes les difference de positions, regroupées par segment\n",
    "trans = data['trans']  # Données de translation donné par smpl-X\n",
    "ltransitions = []   # Liste des transitions relatives frame à frame\n",
    "\n",
    "x = 0\n",
    "y = 0\n",
    "z = 0\n",
    "nbpoints = 2  # Nombre de points de référence correspondant au objet de la scene.\n",
    "ecart = len(trans) // nbpoints  # Espacement entre chaque point\n",
    "\n",
    "for i in range(1, len(trans) - 1):\n",
    "    x += trans[i][0]\n",
    "    y += trans[i][1]\n",
    "    z += trans[i][2]\n",
    "    \n",
    "    # Calcul du déplacement relatif entre la frame suivante et la position cumulée actuelle\n",
    "    ltransitions.append((\n",
    "        trans[i+1][0] - x,\n",
    "        trans[i+1][1] - y,\n",
    "        trans[i+1][2] - z\n",
    "    ))\n",
    "\n",
    "    # Sauvegarde de la translation actuelle\n",
    "    lcoor.append(np.array(trans[i]).tolist())\n",
    "\n",
    "    # Toutes les 'ecart' frames, on sauvegarde la position cumulée et les coordonnées du segment\n",
    "    if i % ecart == 0 and i != 0:\n",
    "        coor.append((x, y, z))\n",
    "        lfinale.append(lcoor)\n",
    "        lcoor = []\n",
    "\n",
    "# Les listes suivantes contiennent :\n",
    "# - coor : positions cumulées à intervalles réguliers\n",
    "# - lfinale : sous-listes des differences de positions par segment\n",
    "# - ltransitions : vecteurs de transition frame à frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def norme(l):\n",
    "  return ( l[0]**2 + l[1]**2 + l[2]**2)\n",
    "\n",
    "\n",
    "temps = []\n",
    "init = 0\n",
    "fin = 0\n",
    "for i in range(len(coor)):\n",
    "  fin += len(lfinale[i])\n",
    "  temps.append((init, fin-1))\n",
    "  init = fin\n",
    "\n",
    "\n",
    "# Créer un dictionnaire Python\n",
    "donnees = {\n",
    "  \"nom\": [],\n",
    "  \"coordonnees\": [],\n",
    "  \"temps\": [],\n",
    "  \"vecteurs\": [],\n",
    "}\n",
    "\n",
    "\n",
    "donnees[\"nom\"] = names\n",
    "donnees[\"coordonnees\"] = coor\n",
    "donnees[\"temps\"] = temps\n",
    "donnees[\"vecteurs\"] = lfinale\n",
    "\n",
    "\n",
    "# Sauvegarder dans un fichier JSON\n",
    "with open(\"fichier.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "  json.dump(donnees, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceac943",
   "metadata": {},
   "source": [
    "# travail final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Définition d'une classe Dataset personnalisée pour PyTorch\n",
    "# Elle permet d'entraîner un modèle à partir d'une séquence de coordonnées et de labels associés\n",
    "# ------------------------------------------------------------\n",
    "class CoordinateSequenceDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "    \n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Fonction de préparation des données d'entrée\n",
    "# Convertit simplement une liste en tenseur PyTorch\n",
    "# ------------------------------------------------------------\n",
    "def setup_data(input_list):\n",
    "    set_sequences = torch.tensor(input_list, dtype=torch.float32)\n",
    "    return set_sequences\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Préparation des données d'entrée (vecteurs) et des labels (poses SMPLX)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "print(len(donnees[\"vecteurs\"]))\n",
    "print(data[\"trans\"].shape)\n",
    "print(donnees[\"vecteurs\"])\n",
    "\n",
    "n_segment = len(donnees[\"vecteurs\"][0])  # Nombre de segments (longueur des séquences)\n",
    "segment_length = len(data[\"poses\"]) // n_segment  # Nombre de poses par segment\n",
    "print(segment_length)\n",
    "\n",
    "# Tronque les poses pour que leur longueur soit un multiple du nombre de segments\n",
    "truncated_poses = data[\"poses\"][:segment_length * n_segment, :66]\n",
    "\n",
    "# Reformate les poses en segments de taille fixe (ici on ne garde que le premier segment avec [:1])\n",
    "reshaped_poses = truncated_poses.reshape(segment_length, n_segment, 66)[:1]\n",
    "\n",
    "# Conversion des listes en tenseurs PyTorch\n",
    "input_data = setup_data(donnees[\"vecteurs\"])\n",
    "labels = setup_data(reshaped_poses)\n",
    "\n",
    "print(input_data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Préparation des ensembles d'entraînement (ici, pas de test split activé)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# train_seq, test_seq, train_labels, test_labels = train_test_split(\n",
    "#     input_data, labels, test_size=0.2, random_state=42\n",
    "# )\n",
    "train_seq, train_labels = input_data, labels\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = CoordinateSequenceDataset(train_seq, train_labels)\n",
    "# test_dataset = CoordinateSequenceDataset(test_seq, test_labels)\n",
    "\n",
    "# Chargement des données par lot (batch)\n",
    "train_loader = DataLoader(train_dataset, batch_size=5000, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Choix du périphérique d'entraînement (GPU si disponible, sinon CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paramètres du modèle\n",
    "# ------------------------------------------------------------\n",
    "sequence_length = len(donnees[\"vecteurs\"][0])  # Longueur des séquences d'entrée\n",
    "input_size = 3                                # Chaque vecteur a 3 dimensions (x, y, z)\n",
    "hidden_size = 100                             # Taille de l'état caché de la GRU\n",
    "output_size = 66                              # Nombre de valeurs de sortie (correspond à la pose)\n",
    "num_epochs = 50\n",
    "batch_size = 5000\n",
    "learning_rate = 0.01\n",
    "num_layers = 2                                # Nombre de couches dans la GRU\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Définition du modèle GRU\n",
    "# Une couche GRU suivie d'une couche linéaire\n",
    "# ------------------------------------------------------------\n",
    "class myGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(myGRU, self).__init__()\n",
    "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialisation de l'état caché à zéro (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.rnn.num_layers, x.size(0), self.rnn.hidden_size).to(device)\n",
    "\n",
    "        # Propagation avant dans la GRU\n",
    "        out, _ = self.rnn(x, h0)  # out : (batch, seq_len, hidden_size)\n",
    "\n",
    "        # Application de la couche linéaire à chaque pas de temps\n",
    "        out = self.fc(out)  # out : (batch, seq_len, output_size)\n",
    "        return out\n",
    "\n",
    "# Instanciation du modèle et déplacement sur le bon périphérique\n",
    "model = myGRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Définition de la fonction de perte et de l'optimiseur\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Boucle d'entraînement du modèle\n",
    "# ------------------------------------------------------------\n",
    "n_total_steps = len(train_loader)\n",
    "print(len(train_loader))\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (sequences, targets) in enumerate(train_loader):\n",
    "        sequences = sequences.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Prédiction\n",
    "        outputs = model(sequences)\n",
    "\n",
    "        # Calcul de la perte\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Rétropropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Affichage de la progression\n",
    "        if (i + 1) % 1 == 0:\n",
    "            print(f'Époque [{epoch+1}/{num_epochs}], Étape [{i+1}/{n_total_steps}], Perte : {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b410fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MESHES \n",
    "\n",
    "poses = model(setup_data(donnees[\"vecteurs\"]))[0]\n",
    "pose_body = torch.tensor(poses[:-1,:66], dtype=torch.float32).to(device) # 21 joints (63 vec) \n",
    "beta = torch.tensor(data['betas'], dtype=torch.float32).unsqueeze(0).repeat(pose_body.shape[0], 1).to(device) \n",
    "\n",
    "meshes = smplx(pose_body=pose_body, betas=beta, use_rodrigues=True)\n",
    "verts = meshes['verts']#.verts_padded()\n",
    "faces = meshes['faces']#.faces_packed()\n",
    "trans = data['trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d5ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['animation.embed_limit'] = 100  # autorise les grandes animations\n",
    "\n",
    "trans_tensor = torch.tensor(data['trans'], dtype=torch.float32).to(device)\n",
    "ani = visualize_seq_with_translation(verts[::40], faces[0].cpu().numpy(), trans_tensor[::40])\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "body",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
